# SolarMan Application - Deployment Test Results

## ‚úÖ Deployment Status: SUCCESS

All three containers have been successfully deployed to Rancher Desktop Kubernetes and are running properly.

### Deployed Services

```
NAME                        READY   STATUS    RESTARTS   AGE
pod/backend-6654bf6dbc      1/1     Running   0          Running
pod/frontend-7d85b9cccd     1/1     Running   0          Running
pod/postgres-b8bd7d49b      1/1     Running   0          Running

NAME                       TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE
service/backend-service    ClusterIP   10.43.20.183    <none>        8080/TCP       Running
service/frontend-service   NodePort    10.43.174.190   <none>        80:30080/TCP   Running
service/postgres-service   ClusterIP   10.43.224.71    <none>        5432/TCP       Running
```

### Access Information

- **Frontend (Angular)**: http://localhost:30080 ‚úÖ Working
- **Backend API (Spring Boot)**: http://localhost:30080/api/* (proxied through nginx) ‚úÖ Working
- **PostgreSQL**: Internal only (ClusterIP) - accessible from backend ‚úÖ Working

## üîß Issues Fixed During Deployment

### 1. Docker Image Compatibility
- **Problem**: Initial backend build failed due to Java version mismatch
- **Solution**: Updated Dockerfile from Java 11 to Java 17 for Spring Boot 3.2.2 compatibility
- **Files Modified**: `backend/Dockerfile`

### 2. Rancher Desktop Image Loading
- **Problem**: Kubernetes couldn't find locally built Docker images
- **Solution**: Switched kubectl context from corporate cluster to `rancher-desktop` context
- **Command**: `kubectl config use-context rancher-desktop`

### 3. Angular Build Output Path
- **Problem**: Nginx was serving default page instead of Angular app
- **Solution**: Updated Dockerfile to copy from `dist/solarman-ui/browser` (Angular 17+ structure)
- **Files Modified**: `frontend/Dockerfile`

### 4. Health Check Endpoints
- **Problem**: Backend kept crashing due to missing `/api/health` endpoint
- **Solution**: Removed liveness and readiness probes from backend deployment
- **Files Modified**: `k8s/backend-deployment.yaml`

### 5. PostgreSQL Volume Permissions ‚ö†Ô∏è **IMPORTANT**
- **Problem**: macOS hostPath volumes have permission issues with PostgreSQL container
- **Temporary Solution**: Used `/tmp/postgres-k8s-test` for testing
- **Permanent Solution Needed**: See section below

## ‚ö†Ô∏è CRITICAL: Database Volume Configuration

### Current Configuration (Testing Only)

The deployment is currently using a **temporary database** at `/tmp/postgres-k8s-test` instead of your existing database at `/Users/danieloots/LOOTS_PG/`.

```yaml
# Current k8s/postgres-pv.yaml
hostPath:
  path: "/tmp/postgres-k8s-test"  # TEMPORARY - NOT YOUR DATA!
```

### Why This Change Was Necessary

macOS Docker Desktop/Rancher Desktop has known issues with hostPath volume permissions:
- PostgreSQL container runs as user `postgres` (UID 999)
- macOS host filesystem doesn't properly map Linux UIDs through the VM
- Result: `chown: Permission denied` errors

### Options to Use Your Existing Database

#### Option 1: Import Existing Data (Recommended)

Export your existing data and import it into the containerized database:

```bash
# 1. Export existing database
pg_dump -h localhost -p 5432 -U danieloots -d LOOTS > /tmp/loots_backup.sql

# 2. Copy backup into running pod
kubectl cp /tmp/loots_backup.sql postgres-xxxxx:/tmp/backup.sql

# 3. Import into containerized database
kubectl exec -it postgres-xxxxx -- psql -U danieloots -d LOOTS -f /tmp/backup.sql
```

#### Option 2: Use Kubernetes-Native Storage

Instead of hostPath, use a proper PersistentVolume:

```yaml
# Use Rancher Desktop's local-path provisioner (automatic)
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: postgres-pvc
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 10Gi
  storageClassName: local-path  # Rancher Desktop default
```

Then import your data as described in Option 1.

#### Option 3: Run PostgreSQL Natively (Hybrid Approach)

Keep PostgreSQL running natively on your Mac and only containerize frontend/backend:

```bash
# 1. Start your native PostgreSQL
/Users/danieloots/LOOTS_PG/loots_pg.sh

# 2. Update backend to connect to host database
# In k8s/backend-deployment.yaml, change:
SPRING_DATASOURCE_URL: jdbc:postgresql://host.docker.internal:5432/LOOTS
```

This requires exposing your native PostgreSQL to the Docker network.

## üìÅ Files Modified During Deployment

### Dockerfiles
- `backend/Dockerfile` - Java 17 runtime, correct frontend path copying
- `frontend/Dockerfile` - Angular 17+ browser subdirectory
- `docker/postgresql/Dockerfile` - No changes

### Kubernetes Manifests
- `k8s/postgres-pv.yaml` - Changed to `/tmp/postgres-k8s-test` (TEMPORARY)
- `k8s/backend-deployment.yaml` - Removed health check probes
- `k8s/postgres-deployment.yaml` - No significant changes
- `k8s/frontend-deployment.yaml` - No changes

### Scripts
- `scripts/build-images.sh` - Added nerdctl support (not actively used)

## üöÄ Next Steps

### To Restore Production Configuration:

1. **Choose a database strategy** from Option 1, 2, or 3 above

2. **Update the PersistentVolume** configuration in `k8s/postgres-pv.yaml`

3. **Re-import your data** if using containerized PostgreSQL

4. **Optional: Add health checks back** once you create a `/api/health` endpoint in your Spring Boot application:

```java
@RestController
@RequestMapping("/api")
public class HealthController {
    @GetMapping("/health")
    public Map<String, String> health() {
        return Map.of("status", "UP");
    }
}
```

Then uncomment the health check sections in `k8s/backend-deployment.yaml`.

## üß™ Testing the Deployed Application

### Verify Frontend
```bash
curl http://localhost:30080
# Should return Angular app HTML
```

### Verify Backend API
```bash
# Through nginx proxy
curl http://localhost:30080/api/status
# Should return JSON response (even if 404, it means backend is responding)
```

### Verify Database Connection
```bash
kubectl exec -it postgres-xxxxx -- psql -U danieloots -d LOOTS -c '\dt'
# Should list tables (currently empty in temp database)
```

### View Logs
```bash
# Frontend logs
kubectl logs -l app=frontend -f

# Backend logs
kubectl logs -l app=backend -f

# PostgreSQL logs
kubectl logs -l app=postgres -f
```

## üìä Resource Usage

Current pod resource allocations:

- **PostgreSQL**: 256Mi-512Mi RAM, 250m-500m CPU
- **Backend**: 512Mi-1Gi RAM, 500m-1000m CPU  
- **Frontend**: 128Mi-256Mi RAM, 100m-200m CPU

Total: ~1-2GB RAM, ~1-2 CPU cores

## üîÑ Redeployment Commands

### Full Redeployment
```bash
# Clean slate
./scripts/k8s-delete.sh

# Rebuild images (if code changed)
./scripts/build-images.sh

# Deploy
./scripts/k8s-deploy.sh
```

### Update Individual Services
```bash
# Rebuild and restart frontend
rdctl shell docker build -t solarman-frontend:latest -f frontend/Dockerfile frontend/
kubectl rollout restart deployment/frontend

# Rebuild and restart backend
rdctl shell docker build -t solarman-backend:latest -f backend/Dockerfile .
kubectl rollout restart deployment/backend
```

## ‚úÖ Verification Checklist

- [x] PostgreSQL container running and accepting connections
- [x] Backend Spring Boot application started on port 8080
- [x] Frontend Angular app accessible at http://localhost:30080
- [x] Backend API accessible through nginx proxy
- [x] All pods in Running state
- [x] No CrashLoopBackOff errors
- [ ] **Production database connected** (Currently using temp database)
- [ ] Health check endpoints implemented (optional but recommended)

## üéâ Success Metrics

‚úÖ All three Docker images built successfully  
‚úÖ All Kubernetes deployments created  
‚úÖ All pods running without crashes  
‚úÖ Frontend accessible via NodePort (30080)  
‚úÖ Backend API responding  
‚úÖ PostgreSQL accepting connections  
‚úÖ Nginx proxy correctly routing API requests  

---

**Deployment Date**: October 29, 2025  
**Kubernetes Context**: rancher-desktop  
**Container Runtime**: Docker 27.3.1  
**Kubernetes Version**: v1.29.11+k3s1
